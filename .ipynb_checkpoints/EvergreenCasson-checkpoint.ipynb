{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "import pandas as pd\n",
      "import ast\n",
      "\n",
      "import numpy as np\n",
      "import scipy as sp\n",
      "import scipy.stats as st\n",
      "from sklearn import cross_validation\n",
      "from sklearn import datasets\n",
      "from sklearn.metrics import confusion_matrix, roc_curve, auc, f1_score\n",
      "from sklearn.externals import joblib\n",
      "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
      "from sklearn.cross_validation import train_test_split\n",
      "\n",
      "import json\n",
      "import nltk\n",
      "import unicodedata\n",
      "\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "from sklearn.feature_extraction.text import TfidfTransformer,TfidfVectorizer\n",
      "from sklearn.linear_model import SGDClassifier\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "from sklearn.pipeline import Pipeline\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def rd_data(filename):\n",
      "    '''Given file name read training data and return a panda data frame.'''\n",
      "    df = pd.DataFrame.from_csv(filename, sep='\\t')\n",
      "    for idx, i in enumerate(df.boilerplate):\n",
      "        try:\n",
      "            df.boilerplate.iloc[idx] = ast.literal_eval(i)\n",
      "        except:\n",
      "            temp = df.boilerplate.iloc[idx].split('null,')\n",
      "            fixed = ''\n",
      "            if len(temp) == 1:\n",
      "                fixed = temp[0]\n",
      "            elif len(temp) == 2:\n",
      "                fixed = (temp[0]+'\"empty\",'+temp[1])\n",
      "            else:\n",
      "                fixed = (temp[0]+'\"empty\",'+temp[1] + '\"empty\",' + temp[2])\n",
      "            df.boilerplate.iloc[idx] = ast.literal_eval(fixed)\n",
      "    return df\n",
      "\n",
      "def vectorize_bagofwords(data):\n",
      "    vectorizer = TfidfVectorizer(min_df=3,strip_accents=None,ngram_range=(1,2),\n",
      "                        stop_words='english',max_features=60000,binary=False,\n",
      "                        norm='l2',use_idf=True,smooth_idf=True,sublinear_tf=True)\n",
      "    #vectorizer = TfidfVectorizer(min_df=1)\n",
      "    #vectorizer = CountVectorizer(min_df=1)\n",
      "    features = []\n",
      "    for i in df.boilerplate:\n",
      "        features.append(i['body'])\n",
      "    features = np.array(features)\n",
      "    # compute Bag of words:\n",
      "    labels = np.array(df['label'])\n",
      "    #ltest_list = unique(labels)\n",
      "    X = vectorizer.fit_transform(features,y=labels)\n",
      "    return X, labels\n",
      "\n",
      "#Note: FPR = 1 - spec\n",
      "def conf_table(mat, ind):\n",
      "    '''Calculate confusion table from specific class of confusion matrix.'''\n",
      "    tp = mat[ind,ind]\n",
      "    fp = sum(mat[ind,:]) - tp\n",
      "    fn = sum(mat[:,ind]) - tp\n",
      "    tn = sum(mat) - tp - fp - fn\n",
      "    ct = np.array([[tp, fp],[fn, tn]])\n",
      "    sens = tp/float(tp + fn)\n",
      "    spec = tn/float(fp + tn)\n",
      "    prec = tp/float(tp + fp)\n",
      "    f1 = 2 * prec * sens / (prec + sens)\n",
      "    return ct, sens, spec, f1\n",
      "\n",
      "import matplotlib as mplt\n",
      "\n",
      "def evaluate1(probs, classes, title='Title'):\n",
      "    '''\n",
      "    Input probabilities and correct classes, plot roc and return auc.\n",
      "    \n",
      "    probs: vector of classification probabilities.\n",
      "    classes: vector of correct classifications.\n",
      "    output: AUC\n",
      "    '''\n",
      "    fpr, tpr, thresholds = roc_curve(classes, probs[:, 1])   \n",
      "    roc_auc = auc(fpr, tpr)\n",
      "    #f1_mnb = f1_score(classes, lpred_test, labels=classes)\n",
      "    print(\"Area under the ROC curve: %f\" % roc_auc)\n",
      "    clf()\n",
      "    plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
      "    plot([0, 1], [0, 1], 'k--')\n",
      "    xlim([0.0, 1.0])\n",
      "    ylim([0.0, 1.0])\n",
      "    xlabel('False Positive Rate')\n",
      "    ylabel('True Positive Rate')\n",
      "    #title('ROC: ' + title)\n",
      "    legend(loc=\"lower right\")\n",
      "    show()\n",
      "    return roc_auc\n",
      "\n",
      "def evaluate(model, test_data, classes, title='Title'):\n",
      "    '''\n",
      "    Input probabilities and correct classes, plot roc and return auc.\n",
      "    \n",
      "    probs: vector of classification probabilities.\n",
      "    classes: vector of correct classifications.\n",
      "    output: AUC\n",
      "    '''\n",
      "    probs = model.predict_proba(test_data)\n",
      "    fpr, tpr, thresholds = roc_curve(classes, probs[:, 1])   \n",
      "    roc_auc = auc(fpr, tpr)\n",
      "    #f1_mnb = f1_score(classes, lpred_test, labels=classes)\n",
      "    print(\"Area under the ROC curve: %f\" % roc_auc)\n",
      "    clf()\n",
      "    plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
      "    plot([0, 1], [0, 1], 'k--')\n",
      "    xlim([0.0, 1.0])\n",
      "    ylim([0.0, 1.0])\n",
      "    xlabel('False Positive Rate')\n",
      "    ylabel('True Positive Rate')\n",
      "    #title('ROC: ' + title)\n",
      "    legend(loc=\"lower right\")\n",
      "    show()\n",
      "    return roc_auc\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Read data in to Pandas\n",
      "df = rd_data('train.tsv')    \n",
      "\n",
      "# Vectorize datad\n",
      "X, labels = vectorize_bagofwords(df)\n",
      "\n",
      "x_train, x_split, labels_train, labels_split = train_test_split(X,labels,test_size=0.4)\n",
      "x_cross, x_test, labels_cross, labels_test = train_test_split(x_split,labels_split,test_size=0.5)\n",
      "\n",
      "bestalpha = 1.4\n",
      "\n",
      "mnb = MultinomialNB(alpha=bestalpha)\n",
      "\n",
      "# Input model that has been fit, test data, and labels\n",
      "evaluate(mnb, x_test, labels_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "AttributeError",
       "evalue": "'MultinomialNB' object has no attribute 'feature_log_prob_'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-30-17d7a7c1c248>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Input model that has been fit, test data, and labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m<ipython-input-22-f7924e93c4fa>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, test_data, classes, title)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0moutput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAUC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     '''\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0mroc_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/zipfianstudent/anaconda/lib/python2.7/site-packages/sklearn/naive_bayes.pyc\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0mare\u001b[0m \u001b[0mordered\u001b[0m \u001b[0marithmetically\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \"\"\"\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_log_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/zipfianstudent/anaconda/lib/python2.7/site-packages/sklearn/naive_bayes.pyc\u001b[0m in \u001b[0;36mpredict_log_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0mare\u001b[0m \u001b[0mordered\u001b[0m \u001b[0marithmetically\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \"\"\"\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mjll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_joint_log_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0;31m# normalize by P(x) = P(f_1, ..., f_n)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mlog_prob_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogsumexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/zipfianstudent/anaconda/lib/python2.7/site-packages/sklearn/naive_bayes.pyc\u001b[0m in \u001b[0;36m_joint_log_likelihood\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    455\u001b[0m         \u001b[0;34m\"\"\"Calculate the posterior log probability of the samples X\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0matleast2d_or_csr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         return (safe_sparse_dot(X, self.feature_log_prob_.T)\n\u001b[0m\u001b[1;32m    458\u001b[0m                 + self.class_log_prior_)\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mAttributeError\u001b[0m: 'MultinomialNB' object has no attribute 'feature_log_prob_'"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mplt."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nnnn\n",
      "###############################################################################\n",
      "# define a pipeline combining a text feature extractor with a simple\n",
      "# classifier\n",
      "pipeline = Pipeline([\n",
      "    ('vect', CountVectorizer()),\n",
      "    ('tfidf', TfidfTransformer()),\n",
      "    ('clf', SGDClassifier()),\n",
      "])\n",
      "\n",
      "# uncommenting more parameters will give better exploring power but will\n",
      "# increase processing time in a combinatorial way\n",
      "parameters = {\n",
      "    'vect__max_df': (0.5, 0.75, 1.0),\n",
      "    #'vect__max_features': (None, 5000, 10000, 50000),\n",
      "    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
      "    #'tfidf__use_idf': (True, False),\n",
      "    #'tfidf__norm': ('l1', 'l2'),\n",
      "    'clf__alpha': (0.00001, 0.000001),\n",
      "    'clf__penalty': ('l2', 'elasticnet'),\n",
      "    #'clf__n_iter': (10, 50, 80),\n",
      "}\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    # multiprocessing requires the fork to happen in a __main__ protected\n",
      "    # block\n",
      "\n",
      "    # find the best parameters for both the feature extraction and the\n",
      "    # classifier\n",
      "    grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\n",
      "\n",
      "    print(\"Performing grid search...\")\n",
      "    print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
      "    print(\"parameters:\")\n",
      "    print(parameters)\n",
      "    #t0 = time()\n",
      "    grid_search.fit(x_train[0:100], labels_train[0:100])\n",
      "    #print(\"done in %0.3fs\" % (time() - t0))\n",
      "    print()\n",
      "\n",
      "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
      "    print(\"Best parameters set:\")\n",
      "    best_parameters = grid_search.best_estimator_.get_params()\n",
      "    for param_name in sorted(parameters.keys()):\n",
      "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'nnnn' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-13-9477e822b621>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnnnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m###############################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# define a pipeline combining a text feature extractor with a simple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m pipeline = Pipeline([\n",
        "\u001b[0;31mNameError\u001b[0m: name 'nnnn' is not defined"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from bs4 import BeautifulSoup\n",
      "import requests\n",
      "\n",
      "def get_page(filenum):\n",
      "    r  = requests.get(u'file:///Users/zipfianstdudent/Evergreen/raw_content/' + str(filenum))\n",
      "    page = r.text\n",
      "    soup = BeautifulSoup(page)\n",
      "    for link in soup.find_all('a'):\n",
      "        print link.get('href')\n",
      "get_page(1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "InvalidURL",
       "evalue": "Invalid URL u'file:///Users/zipfianstudent/Evergreen/raw_content/1': No host supplied",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mInvalidURL\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-13-9659ee79271e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlink\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0mlink\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'href'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mget_page\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m<ipython-input-13-9659ee79271e>\u001b[0m in \u001b[0;36mget_page\u001b[0;34m(filenum)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_page\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilenum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mr\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"file:///Users/zipfianstudent/Evergreen/raw_content/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilenum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mpage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/zipfianstudent/anaconda/lib/python2.7/site-packages/requests/api.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/zipfianstudent/anaconda/lib/python2.7/site-packages/requests/api.pyc\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/zipfianstudent/anaconda/lib/python2.7/site-packages/requests/sessions.pyc\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;31m# Prepare the Request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0mprep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/zipfianstudent/anaconda/lib/python2.7/site-packages/requests/models.pyc\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m         \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_headers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_cookies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcookies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/zipfianstudent/anaconda/lib/python2.7/site-packages/requests/models.pyc\u001b[0m in \u001b[0;36mprepare_url\u001b[0;34m(self, url, params)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhost\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mInvalidURL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid URL %r: No host supplied\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;31m# Only want to apply IDNA to the hostname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mInvalidURL\u001b[0m: Invalid URL u'file:///Users/zipfianstudent/Evergreen/raw_content/1': No host supplied"
       ]
      }
     ],
     "prompt_number": 13
    }
   ],
   "metadata": {}
  }
 ]
}